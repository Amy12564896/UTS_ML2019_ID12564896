{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Copy of A1_ReportDraft.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amy12564896/UTS_ML2019_ID12564896/blob/master/A1_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeYZlpLJiBgq",
        "colab_type": "text"
      },
      "source": [
        "# Draft and Experiment Area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5Jv62GZzvIP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C7Tu3RoiBgy",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on \"Eigenfaces vs Fisherfaces: Recognition using Class Specific Linear Projection \"\n",
        "\n",
        "Link: https://github.com/Amy12564896/UTS_ML2019_ID12564896/blob/master/A1_Report.ipynb "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWVYKPxciBg1",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Facial recognition technology is becoming more integrated into many fields - from government healthcare and security to commercial use where purchases can be made using a facial scan. As with all technology it has developed at an extraordinary rate, this review is examining the paper 'Eigenfaces vs Fisherfaces: Recognition using Class Specific Linear Projection' by Belhumeaur P., Hespanha J. and Kriegman D in 1997. The paper introduces a new algorithm called Fisherfaces and compares it to pre-existing algorithms through testing on two datasets to inspect if Fisherfaces solves the issues with lighting variability and facial expression changes that the current methods struggle with. This report works to summarise the papers content, highlight it's innovation in 1997, evaluate the technical quality, the proposed application domains and presentation of the paper. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPkKbSeziBg2",
        "colab_type": "text"
      },
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFakmeI_iBg5",
        "colab_type": "text"
      },
      "source": [
        "This paper investigates various methods for facial recognition with specific regard to how different algorithms perform in response to different lighting conditions and facial expressions. Expressions do not distort the key features too dramatically however at the time this paper was produced,  there was still enough of an alteration to the facial structure of a subject that significant expression changes would lower accuracy of a recognition system. Regarding lighting variations, when examining general image and pattern recognition with strong lighting using a fixed image of a Lambertian surface - where the light reflects uniformly when under different light sources therefore should be ideal for recognition (AZoOptics 2014) – it will yield unreliable results due to the shadowing that differs in each image. For facial recognition, the direction and intensity of lighting can dramatically change the shape and primary features of a face to the extent that two images of the same face can be almost unrecognisable for the human eye highlighting the importance of training computer vision to recognise these changes.   \n",
        "\n",
        "This is a major challenge for widespread use of facial recognition as the environment in which a face is found will not be identical each time. Facial expressions change frequently, with none looking identical between people, whilst lighting can vary dramatically in the diverse environments facial recognition may be used. Therefore, overcoming these environmental elements such as lighting is critical for expanding applications. \n",
        "\n",
        "The paper works to resolve this through experimenting with the Fisherface algorithm - based off the classical technique in pattern recognition known as Fisher’s Linear Discriminant (FLD) (Thalles Blog 2019) – which is a class specific method that works to shape the scatters produced into a lower dimensionality space for faster computational time with more reliable results. Fisherface is tested on two different datasets with different light sources and facial expressions, these results are compared against Correlation, Linear Subspaces and Eigenfaces approaches on the same datasets in the same conditions. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vWLBdbgiBg7",
        "colab_type": "text"
      },
      "source": [
        "## Innovation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqB-tyCbiBg9",
        "colab_type": "text"
      },
      "source": [
        "Belhumeur, Hespanha and Kriegman contribute a new algorithm in their development of Fisherface. It has been presented alongside a comparison of other methods with experimentation on correlation, eigenfaces and linear subspace algorithms to contrast their performance against the new Fisherface approach. \n",
        "\n",
        "The comparison between the different algorithms is not only through experimentation of datasets to evaluate the different error rates testing different lighting conditions and facial expressions rather including overarching appropriate applications for each technique whilst also the disadvantages. The layout of the paper allows for all previous methods to be outlined with their disadvantages explained to demonstrate how Fisherface works to resolve these issues.  As Fisherfaces combats the poor clustering of results that may be too loosely clustered or smeared together and the high storage or computational demand. \n",
        "\n",
        "\n",
        "The new algorithm is a combination of Principal Component Analysis (PCA) and Fisher Linear Discriminant (FLD). The Fisher Linear Discriminant is a classical method that minimises class overlap through maximising the ratio between class variance to the within class variance. This works to lower the dimensionality whilst still preserving linear separability (Thalles Blog 2019). As previously PCA methods have smeared classes together which removes linear separability in the projected spaces which increases error in classification (Jaadi 2019). The ingenuity of the Fisherface method is to apply PCA to achieve a large total scatter and then apply a standard FLD to have greater between class scatter to simplify the classification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE7Wml59iBg_",
        "colab_type": "text"
      },
      "source": [
        "## Technical quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP3mDbbKiBhB",
        "colab_type": "text"
      },
      "source": [
        "The paper performed three different experiments on two different datasets to evaluate the new algorithm against pre-existing methods using error rates for comparison. The first experiment uses the Harvard dataset and performs extrapolation and interpolation by first dividing the dataset into five subsets. The extrapolation test results could be considered misleading as the table shows the first subset results which is the same as the training set therefore has zero error. The table then compares the error rates for subsets two and three which have less variation of lighting conditions than four and five which are not included.  There is no explanation as to why these subsets were not included – the resulting table is very positive for the error rates found which may be misleading without knowing the other subset outcomes. Whilst the interpolation was trained on subsets one and five to get the results shown in the table from subsets two, three and four. This seems to be a better indication of the performance of the methods.\n",
        "\n",
        "![Images of Subsets](https://i.imgur.com/QOUciNE.jpg)\n",
        "\n",
        "\n",
        "> Image 1 (Belhumeaur, Hespanha & Kriegman 1997)\n",
        "\n",
        "\n",
        "\n",
        "The second experiment used the ‘leaving one out’ strategy for error rates to work towards unbiased results. Performed on the second dataset from Yale the results from this test are compared directly to those from test one – which could be misleading as the two datasets are not comparable as the conditions that images are under in each dataset are vastly different. The second dataset includes various lighting sources, expression changes and how the image – therefore any number of these variables could cause the change in error rates, it is hard to pinpoint what exactly would be making results worse. However, this experiment is useful as it takes in higher variability between images which is more realistic to how this technology will be used in future applications. \n",
        "\n",
        "![Yale Dataset Image examples](https://i.imgur.com/6yre5Rd.jpg)\n",
        "\n",
        "\n",
        "> Image 2 (Belhumeaur, Hespanha & Kriegman 1997)\n",
        "\n",
        "\n",
        "\n",
        "To improve the experiment results it would be better to create more subsets from the Harvard database and compare them all – even if just the highlights but stating that all were tested to understand if some lighting conditions were more influential to results than others. Additionally, the extrapolation test should be repeated using different training sets as the first subset used for training was the most clearly lit compared to others which will not always be true in what data can be collected. For the second test, it would be better to perform a series of tests - with each individual variable changing to find where areas of weakness may be. The paper overall does three tests which is not enough to conclude that Fisherfaces is outperforming the other methods especially as the Linear Subspace method also performs well.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_kEsNnXiBhC",
        "colab_type": "text"
      },
      "source": [
        "## Application and X-factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9S2IsA9iBhD",
        "colab_type": "text"
      },
      "source": [
        "The Fisherfaces algorithm is appropriately applied in image recognition with specific focus on facial recognition. To extend the use of the algorithm (from a 1997 perspective) research into the nature of how faces can change in different conditions - natural light compared to artificial, can faces be recognised when wearing sunglasses - this paper addresses clear glasses not tinted - or if half a face could be affective in facial recognition to make a more robust algorithm. This could build towards video facial recognition that would have to combat lower quality and blurred faces. \n",
        "\n",
        "This 22-year-old seminal paper for Fisherfaces offers insight into how facial recognition has been developed and how quickly it has gone from still photos under very controlled conditions to personal security for modern mobiles and laptops as a security measure. Other applications could be commercial purchasing rather than using a card or phone or in social media to find friends in images to be 'tagged'. The use of facial recognition has been part of law enforcement for many years however as it becomes more sophisticated it has become useful across a breadth of police work. Beyond facial recognition - as Fisherface at its core is a recognition algorithm - it could be applied to other domains such as environmental areas where it could recognise the same species amongst other plants or identify if a fauna/flora is healthy or not. There are many environmental applications that could benefit from such pattern recognition outlined in the Fisherfaces capabilities. \n",
        "\n",
        "However the paper does not discuss the ethical implications of the technology it is developing – which now over two decades on see the use by the Chinese Government is using facial recognition on a large scale for ethically grey reasons (Mozur 2019). Belhumeur, Hespanha and Kriegman should have discussed the ethics of their work as it is a critical part of technology development to consider the potential unethical uses and work to mitigate them. However at the speed this technology is moving it is difficult, with newer algorithms evolving that are effective in real time such as the Viola-Jones method that uses neural networks (Kharkovyna 2019).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFztLFuTiBhF",
        "colab_type": "text"
      },
      "source": [
        "## Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE3uErkqiBhH",
        "colab_type": "text"
      },
      "source": [
        "The paper was clear and succinct in its comparison of techniques and introduction of the Fisherface algorithm. The headings were clear in following the thought processes of the authors to understand how the problem was identified and approached. The previously developed methods were explained with disadvantages highlighted; however, the paper could have explored greater breadth of context that may have assisted in understanding some concepts that were brought up when discussing the different algorithms. Rather I had to research these acronyms to make sense of them – the paper was very much written for other academics in the same field. This is only reinforced as the paper became more technical in its descriptions of the algorithms and tests. The methods used for testing and errors were not clear and when discussing results, the structure that had been useful in following in the first part of the paper felt lost and it became jumbled between different methods performances. \n",
        "\n",
        "The paper could have been improved by including footnotes that explained some concepts that may have been new to a reader therefore making it easier to digest the high level of technical information being put forward. Additionally, organising the results section differently to discuss how each method performed and potential reasons for this would have allowed for greater clarity and consistency in comparison of the methods rather than simply not mentioning some of the methods. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z4G0IfZiBhJ",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "AZoOptics, 2014, ‘What is a Lambertian Surface?’, *AZO Optics*, 9 October, viewed 15 August 2019, < https://www.azooptics.com/Article.aspx?ArticleID=790 >.\n",
        "\n",
        "Belhumeaur P., Hespanha J., Kriegman D., 1997, 'Eigenfaces vs Fisherfaces: Recognition using Class Specific Linear Projection', *IEEE Transactions on Pattern Analysis a nd Machine Intelligence*, vol. 19, no. 7, pp. 7117-721\n",
        "\n",
        "Jaadi Z., 2019, ‘A step by step explanation of Principal Component analysis’, *Towards Data Science*, 28 February, viewed 15 August 2019, < https://towardsdatascience.com/a-step-by-step-explanation-of-principal-component-analysis-b836fb9c97e2 >.\n",
        "\n",
        "Kharkovyna O, 2019, ‘An Intro to Deep Learning for Face Recognition’, *Towards Data Science*, 26 June, viewed 23 August 2019, < https://towardsdatascience.com/an-intro-to-deep-learning-for-face-recognition-aa8dfbbc51fb >.\n",
        "\n",
        "Mozur P., 2019, ‘One Month, 500,000 Face Scans: How China Is Using A.I. to Profile a Minority’, *New York Times*, April 14, viewed 20 August 2019, < https://www.nytimes.com/2019/04/14/technology/china-surveillance-artificial-intelligence-racial-profiling.html >. \n",
        "\n",
        "Thalles Blog, 2019, *An illustrative introduction to Fisher’s Linear Discriminant*, 3 January, viewed 15 August 2019, < https://sthalles.github.io/fisher-linear-discriminant/ >.\n"
      ]
    }
  ]
}