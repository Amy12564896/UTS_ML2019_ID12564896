{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3_Exam.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amy12564896/UTS_ML2019_ID12564896/blob/master/A3_Exam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riApelgpVRx4",
        "colab_type": "text"
      },
      "source": [
        "# Question 3\n",
        "Marketing or advertising companies would be very interested in being able to predict whether a Twitter message will spread as a meme or not, and even better, construct it so that it will spread. Why is this a hard problem to solve? Describe two appraoches using data analytics to predict whether a tweet will go viral or not. How would you validate these approaches? Discuss the ethical and social consequence of this study.\n",
        "\n",
        "\n",
        "- Relevant to the question\n",
        "- Technical sound - assessed by either theoretical proof or reasonable hyppothetical arguments\n",
        "- Proposed solution can be practically feasable - convinced by logical argument in report\n",
        "- Report contains sufficient background research of existing solutions to related or similar problems\n",
        "- More ossible methods considered - proposed method is well motivated among alternatives.\n",
        "- Clear structure, well written. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKnODyrUiMWe",
        "colab_type": "text"
      },
      "source": [
        "# Challenges\n",
        "With the copious amounts of data being collected there are more opportunities to predict trends and adjust business strategies to align with these insights. Social media platforms are a forum of content creation by businesses and consumers which has allowed for the emergence of memes which gain popularity at incredibly rates from seemingly anywhere. The task to predict if content – a Tweet - will become viral and extend that into creating ‘meme-worthy’ content is a complex problem. There are many elements that feed into the challenge of predicting viral content such as memes including volume, spontaneity, time and content.\n",
        "\n",
        "> *‘There are around 400 h of video content uploaded to YouTube every minute and around 500 million tweets created on Twitter every day.’* (Huang et al 2019 pp. 1).\n",
        "\n",
        "The volume of content being generated and spread through social media that it is overwhelming and user attention is only held by so much therefore very limited percentages of content gain high levels of traffic (6). \n",
        "\n",
        "Coupled with the constant nature of this content creation the nature of the memes is reactive and spontaneous. Memes have highly dynamic behavior as the topics can change instantly and often the most viral ones respond to live worldwide events which increases the difficulty in prediction (8). Due to the instantaneous nature of Tweets and the memes within this platform the time period in which content receives popularity can span from hours to weeks which Huang et al (2019) refer to as the ‘Active Period’. Those memes that hit peak popularity within hours and decay equally as quickly are called ‘Bursting Hashtags’ which can be extremely unsystematic to other trends in the media which add another layer of complexity when working to predict the future popularity of tweets (Xua et al 2018). Conventional prediction models work off historical statistics and trends which memes do not always adhere to as they are highly reactive to changes in global affairs which is a complex relationship to capture between users (Wang et al 2018 & 10). Tweets are particularly tricky to compute as Twitter as a platform hyperbolizes the issues mentioned above as the content is limited in length therefore the flow of information is constant and noisy as users instantly react to world events (7). \n",
        "\n",
        "![Tweet Meme text above man in hosptial bed with female nurse reading: Nurse: Sir... you've been in a coma since 2017. Me: Do people still use this meme format? Nurse: Yesn't. Me: What?](https://i.imgur.com/xxwoB3Vm.jpg)\n",
        "\n",
        "This response will describe two research papers that predict future popularity of online content using Tweets and Facebook news pages as their data sources. Together they provide a rounded view of predicting viral online content. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fFFN_8m9SIc",
        "colab_type": "text"
      },
      "source": [
        "# Approach 1\n",
        "The first approach by Huang et al (2019) uses 3million hashtags across 40million users in a Deep Neural Network Framework to create their prediction model. The research this paper adds to this field is including both dynamic and static factors into the same model as previous research often consider them separately. Dynamic factors are those that change over time such as User Statistics, Accumulation Time and Topological Network formed by users discussing a hashtag which are embedded using Long Short Term Memory (LSTM). Whilst static factors are those that consider content of the Tweets themselves and the age of the content which are embedded using a Convolutional Neural Network (CNN) Another distinction Huang et al (2019) make from other work is to use a trigger level to begin predictions rather than a fixed time – this is due the volatility the time factor has in Tweet popularity to ensure that the model captures the entire ‘Active Period’. \n",
        "\n",
        "Firstly, to combine the Dynamic features the Deep Walk algorithm is used to embed the Topological Network - where users who Tweet the hashtag are assessed for relationships and connected if this is true – together with the accumulated popularity over a time period. This topological network is then concatenated with the user statistics – which collects the celebrities involved in the hashtag and their fans. This is then sent to the LSTM which decides what information is useful to be stored in cell states. The static factors extract from the hashtag a string feature – a vector composed of string length and individual words in string counted – and the lexical feature which is extracted by word embedding and the CNN. These are then concatenated together into a vector and apply a max pooling layer to the output followed by a dense fixed number of neurons layer is applied to the output of the pooling layer. It is then logarithmically normalized and trained by minimizing the cost function. The results showed that the higher the trigger level results in higher accuracy based on an Absolute Percentage Error evaluation and a stronger right skew than other baseline models across all trigger levels (Support Vector Regression, SpikeM and Neural Networks).\n",
        "\n",
        "\n",
        "# Validation \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWNgnx8P9iZK",
        "colab_type": "text"
      },
      "source": [
        "# Approach 2\n",
        "The second approach to solve this task is by Wang et al (2017) where they suggest that introducing the weak ties in a social network will improve the accuracy of viral spread predictions. This combines human network theory where weak ties play important roles in diffusing information and in prediction models previously the referrer of the information is a strongest driver for consumption of content online (Huang 2019). Sourcing the dataset from Facebook in their model with a 3hour initial observe time for predictions Wang et al (2017) use a classic popularity prediction model providing linear regression for early and final popularity. The model is created by initially creating strong ties between users are already connected who share content, this is then adjusted to include the proportion of strong ties users who leave comments. This is then added to the offset at a specific time caused by competitive diffusion. Where the offset is calculated through a probability vector with semantic classification of news into possible categories – as five different news outlets might be reporting the same story. The model performs better than the classical one – evaluated using Root Mean Squared Error) resulting in differences of up to 0.138 less error. \n",
        "\n",
        "# Validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RBdQLDe9l-y",
        "colab_type": "text"
      },
      "source": [
        "# Ethical and Social Consequence "
      ]
    }
  ]
}